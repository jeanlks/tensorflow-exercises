{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_DATA/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HELPER \n",
    "\n",
    "#INIT WEIGHTS\n",
    "\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "#INIT BIAS\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "#CONV2D\n",
    "def conv2d(x,W):\n",
    "    #x -> [H,W,Channels]\n",
    "    #W -> [filter H, filter W, Channels In, Channels Out]\n",
    "    return tf.nn.conv2d(x,W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "#POOLING\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    #x --> [batch, h,w,c]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CONVOLUTIONAL LAYER\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NORMAL LAYER (FULLY CONNECTED)\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLACEHOLDERS \n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LAYERS \n",
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x_image, shape=[5,5,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling, shape=[5,5,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOSS FUNCTION\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OPTIMIZER\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZED TRAINING\n",
      "ON STEP 0\n",
      "ACCURACY \n",
      "0.128\n",
      "\n",
      "\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n",
      "INITIALIZED TRAINING\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch_x, batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(train, feed_dict={x:batch_x, y_true:batch_y, hold_prob:0.50})\n",
    "        if i%100 == 0:\n",
    "            print('ON STEP {}'.format(i))\n",
    "            print('ACCURACY ')\n",
    "            matches = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(acc, feed_dict={x:mnist.test.images, y_true: mnist.test.labels, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
